# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VgEi5dct4YeRXtGaBvI7WfZrg6M6P85S
"""

!pip install gradio opencv-python-headless numpy pillow plotly pandas -q

import gradio as gr
import cv2
import numpy as np
from PIL import Image
import datetime
import pandas as pd
import tempfile
import os
import plotly.graph_objects as go
import plotly.express as px
from collections import deque

class DhristiCrowdAnalyzer:
    def __init__(self):
        self.alerts = []
        self.analytics_data = []
        self.safe_threshold = 150
        self.moderate_threshold = 250
        self.critical_threshold = 350
        self.motion_history = deque(maxlen=30)
        self.prev_frame = None

    def detect_anomaly(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (21, 21), 0)

        if self.prev_frame is None:
            self.prev_frame = gray
            return False, 0.0

        frame_diff = cv2.absdiff(self.prev_frame, gray)
        _, thresh = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)
        motion_intensity = np.sum(thresh) / (frame.shape[0] * frame.shape[1])
        self.motion_history.append(motion_intensity)

        if len(self.motion_history) >= 10:
            avg_motion = np.mean(list(self.motion_history)[:-5])
            recent_motion = np.mean(list(self.motion_history)[-5:])
            is_anomaly = recent_motion > (avg_motion * 3) and recent_motion > 50.0
        else:
            is_anomaly = False

        self.prev_frame = gray
        return is_anomaly, motion_intensity

    def create_density_map(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (25, 25), 0)
        jet_heatmap = cv2.applyColorMap(blurred, cv2.COLORMAP_JET)
        overlay = cv2.addWeighted(frame, 0.5, jet_heatmap, 0.5, 0)
        return overlay

    def draw_crowd_zones(self, frame):
        h, w = frame.shape[:2]
        overlay = frame.copy()

        zones = [
            ((0, 0), (w//3, h), (0, 255, 0), "ZONE A"),
            ((w//3, 0), (2*w//3, h), (255, 255, 0), "ZONE B"),
            ((2*w//3, 0), (w, h), (255, 0, 0), "ZONE C")
        ]

        for (x1, y1), (x2, y2), color, label in zones:
            cv2.rectangle(overlay, (x1, y1), (x2, y2), color, 2)
            cv2.putText(overlay, label, (x1+10, y1+30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        result = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        return result

    def analyze_image(self, image, location, show_zones, show_contours):
        if image is None:
            return None, None, None, None, "‚ö†Ô∏è Please upload an image", None

        frame = np.array(image)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        frame = cv2.resize(frame, (640, 480))

        results = self.process_frame(frame, location, show_zones, show_contours)

        report = self.generate_detailed_report(
            results['crowd_count'],
            results['danger_level'],
            results['emoji'],
            location,
            results['is_anomaly'],
            results['motion']
        )

        gauge = self.create_gauge_chart(results['crowd_count'])

        return results['annotated'], results['heatmap'], results['zones'], gauge, report, self.get_alert_table()

    def analyze_video(self, video, location, show_zones, show_contours, progress=gr.Progress()):
        if video is None:
            return None, None, None, "‚ö†Ô∏è Please upload a video"

        cap = cv2.VideoCapture(video)

        if not cap.isOpened():
            return None, None, None, "‚ùå Error: Could not open video"

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        output_path = tempfile.mktemp(suffix='.mp4')
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (640, 480))

        frame_num = 0
        max_crowd = 0
        danger_frames = {'SAFE': 0, 'MODERATE': 0, 'HIGH': 0, 'CRITICAL': 0}
        crowd_timeline = []
        anomaly_count = 0

        progress(0, desc="üé¨ Starting video analysis...")

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame = cv2.resize(frame, (640, 480))

            if frame_num % 3 == 0:
                results = self.process_frame(frame, location, show_zones, show_contours)

                crowd_count = results['crowd_count']
                danger_level = results['danger_level']
                is_anomaly = results['is_anomaly']

                crowd_timeline.append({
                    'frame': frame_num,
                    'time': frame_num/fps,
                    'count': crowd_count,
                    'level': danger_level
                })

                max_crowd = max(max_crowd, crowd_count)
                danger_frames[danger_level] += 1
                if is_anomaly:
                    anomaly_count += 1

                out.write(cv2.cvtColor(results['annotated'], cv2.COLOR_RGB2BGR))

                progress(frame_num / total_frames, desc=f"üé• Processing: {frame_num}/{total_frames}")
            else:
                out.write(frame)

            frame_num += 1

        cap.release()
        out.release()

        timeline_chart = self.create_timeline_chart(crowd_timeline)
        distribution_chart = self.create_distribution_chart(danger_frames)
        report = self.generate_video_report(crowd_timeline, max_crowd, danger_frames, anomaly_count, fps, location)

        return output_path, timeline_chart, distribution_chart, report

    def process_frame(self, frame, location, show_zones=True, show_contours=False):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (21, 21), 0)
        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY_INV, 11, 2)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        valid_contours = [c for c in contours if cv2.contourArea(c) > 100]

        crowd_count = int(len(valid_contours) * 2.5)
        is_anomaly, motion = self.detect_anomaly(frame)

        if crowd_count > self.critical_threshold:
            danger_level, emoji, color = "CRITICAL", "üî¥", (0, 0, 255)
        elif crowd_count > self.moderate_threshold:
            danger_level, emoji, color = "HIGH", "üü†", (0, 165, 255)
        elif crowd_count > self.safe_threshold:
            danger_level, emoji, color = "MODERATE", "üü°", (0, 255, 255)
        else:
            danger_level, emoji, color = "SAFE", "üü¢", (0, 255, 0)

        if danger_level in ["HIGH", "CRITICAL"] or is_anomaly:
            self.alerts.append({
                'Time': datetime.datetime.now().strftime("%H:%M:%S"),
                'Location': location,
                'Level': danger_level,
                'Count': crowd_count,
                'Anomaly': '‚ö†Ô∏è YES' if is_anomaly else 'NO'
            })

        annotated = frame.copy()

        if show_contours:
            cv2.drawContours(annotated, valid_contours, -1, (0, 255, 0), 2)

        cv2.rectangle(annotated, (0, 0), (640, 140), (0, 0, 0), -1)
        cv2.rectangle(annotated, (0, 0), (640, 140), color, 5)

        cv2.putText(annotated, f"LOCATION: {location}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(annotated, f"{emoji} {danger_level}", (10, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)  # FIXED: Changed from FONT_HERSHEY_BOLD
        cv2.putText(annotated, f"CROWD: {crowd_count} people", (10, 110),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        cv2.putText(annotated, timestamp, (420, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

        bar_width = int((crowd_count / 500) * 620)
        cv2.rectangle(annotated, (10, 450), (bar_width, 470), color, -1)
        cv2.rectangle(annotated, (10, 450), (630, 470), (255, 255, 255), 2)

        if is_anomaly:
            cv2.rectangle(annotated, (10, 150), (630, 200), (0, 0, 255), -1)
            cv2.putText(annotated, "WARNING: UNUSUAL MOVEMENT!", (20, 180),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)  # FIXED: Changed from FONT_HERSHEY_BOLD

        heatmap_overlay = self.create_density_map(frame)
        zones_frame = self.draw_crowd_zones(frame) if show_zones else frame.copy()

        return {
            'annotated': cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB),
            'heatmap': cv2.cvtColor(heatmap_overlay, cv2.COLOR_BGR2RGB),
            'zones': cv2.cvtColor(zones_frame, cv2.COLOR_BGR2RGB),
            'crowd_count': crowd_count,
            'danger_level': danger_level,
            'emoji': emoji,
            'color': color,
            'is_anomaly': is_anomaly,
            'motion': motion
        }

    def create_gauge_chart(self, crowd_count):
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = crowd_count,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "Crowd Count", 'font': {'size': 24}},
            delta = {'reference': self.safe_threshold},
            gauge = {
                'axis': {'range': [None, 500]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, self.safe_threshold], 'color': '#90EE90'},
                    {'range': [self.safe_threshold, self.moderate_threshold], 'color': '#FFD700'},
                    {'range': [self.moderate_threshold, self.critical_threshold], 'color': '#FFA500'},
                    {'range': [self.critical_threshold, 500], 'color': '#FF4444'}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': self.critical_threshold
                }
            }
        ))

        fig.update_layout(height=300)
        return fig

    def create_timeline_chart(self, timeline_data):
        df = pd.DataFrame(timeline_data)

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=df['time'], y=df['count'],
            mode='lines+markers',
            name='Crowd Count',
            line=dict(color='#FF4B4B', width=3)
        ))

        fig.add_hline(y=self.safe_threshold, line_dash="dash", line_color="green")
        fig.add_hline(y=self.moderate_threshold, line_dash="dash", line_color="orange")
        fig.add_hline(y=self.critical_threshold, line_dash="dash", line_color="red")

        fig.update_layout(
            title="Crowd Count Timeline",
            xaxis_title="Time (seconds)",
            yaxis_title="People Count"
        )

        return fig

    def create_distribution_chart(self, danger_frames):
        labels = list(danger_frames.keys())
        values = list(danger_frames.values())
        colors = ['#90EE90', '#FFD700', '#FFA500', '#FF4444']

        fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4, marker_colors=colors)])
        fig.update_layout(title="Danger Level Distribution")

        return fig

    def generate_detailed_report(self, crowd_count, danger_level, emoji, location, is_anomaly, motion):
        report = f"""
# üö® DHRISTI ANALYSIS REPORT

## Status: {emoji} **{danger_level}**

### üìç Location: {location}
### ‚è∞ Time: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

## üìä CROWD METRICS

| Metric | Value |
|--------|-------|
| **People Count** | {crowd_count} |
| **Safe Threshold** | < {self.safe_threshold} |
| **Critical Threshold** | > {self.critical_threshold} |

---
"""

        if is_anomaly:
            report += f"""
### üö® ANOMALY DETECTED!
- Unusual crowd movement
- Motion intensity: {motion:.2f}
- Possible panic situation

"""

        if danger_level == "CRITICAL":
            report += f"""
### üî¥ CRITICAL EMERGENCY

**{crowd_count} people - {crowd_count - self.critical_threshold} OVER LIMIT!**

**IMMEDIATE ACTIONS:**
1. üö® STOP all entry
2. üö™ Open emergency exits
3. üëÆ Deploy all officers
4. üì¢ Begin announcements
5. üöë Medical teams standby
"""
        elif danger_level == "HIGH":
            report += f"""
### üü† HIGH ALERT

**{crowd_count} people - Approaching critical**

**ACTIONS:**
1. ‚ö†Ô∏è Reduce entry by 75%
2. üëÆ Deploy additional officers
3. üìπ Monitor closely
4. üîä Prepare crowd control
"""
        elif danger_level == "MODERATE":
            report += f"""
### üü° MODERATE CAUTION

**{crowd_count} people - Above safe threshold**

**ACTIONS:**
1. üëÅÔ∏è Monitor every 5 minutes
2. üëÆ Officers on standby
3. üìä Track trends
"""
        else:
            report += f"""
### ‚úÖ SAFE CONDITIONS

**{crowd_count} people - Within safe limits**

**ACTIONS:**
1. ‚úÖ Continue normal operations
2. üëÅÔ∏è Routine monitoring
"""

        return report

    def generate_video_report(self, timeline, max_crowd, danger_frames, anomaly_count, fps, location):
        avg_crowd = np.mean([t['count'] for t in timeline]) if timeline else 0
        total = sum(danger_frames.values())

        report = f"""
# üé• VIDEO ANALYSIS REPORT

## üìç Location: {location}
## üìÖ Date: {datetime.datetime.now().strftime("%Y-%m-%d")}

---

## üìä SUMMARY

| Metric | Value |
|--------|-------|
| **Frames Analyzed** | {total} |
| **Average Crowd** | {avg_crowd:.0f} people |
| **Peak Crowd** | {max_crowd} people |
| **Anomalies** | {anomaly_count} |

---

## ‚ö†Ô∏è DANGER LEVELS

| Level | Frames | Percentage |
|-------|--------|------------|
| üü¢ SAFE | {danger_frames['SAFE']} | {danger_frames['SAFE']/total*100:.1f}% |
| üü° MODERATE | {danger_frames['MODERATE']} | {danger_frames['MODERATE']/total*100:.1f}% |
| üü† HIGH | {danger_frames['HIGH']} | {danger_frames['HIGH']/total*100:.1f}% |
| üî¥ CRITICAL | {danger_frames['CRITICAL']} | {danger_frames['CRITICAL']/total*100:.1f}% |

---

## üéØ ASSESSMENT
"""

        if max_crowd > self.critical_threshold:
            report += f"""
### üî¥ CRITICAL SITUATION

Peak of {max_crowd} people exceeded limits!

**RECOMMENDATIONS:**
- Immediate protocol review
- Enhanced crowd management
- Additional security deployment
"""
        else:
            report += f"""
### ‚úÖ OPERATIONS SAFE

Crowd management effective throughout.
"""

        return report

    def get_alert_table(self):
        if not self.alerts:
            return pd.DataFrame()
        return pd.DataFrame(self.alerts[-20:])

# Initialize
analyzer = DhristiCrowdAnalyzer()

# Create Interface
with gr.Blocks(theme=gr.themes.Soft(), title="Dhristi") as demo:

    gr.Markdown("""
    <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px;'>
        <h1 style='color: white; font-size: 3em; margin: 0;'>üö® DHRISTI</h1>
        <h2 style='color: #f0f0f0;'>AI-Powered Crowd Management System</h2>
    </div>
    """)

    with gr.Tabs():
        with gr.Tab("üì∑ Image Analysis"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### üì§ Upload Image")
                    image_input = gr.Image(type="pil", label="Upload Crowd Image")
                    location_input = gr.Textbox(value="Main Entrance", label="üìç Location")

                    with gr.Accordion("‚öôÔ∏è Options", open=False):
                        show_zones = gr.Checkbox(label="Show Safety Zones", value=True)
                        show_contours = gr.Checkbox(label="Show Contours", value=False)

                    analyze_btn = gr.Button("üîç Analyze", variant="primary", size="lg")

                    gr.Markdown("""
                    ### üéØ Thresholds
                    - üü¢ SAFE: < 150
                    - üü° MODERATE: 150-250
                    - üü† HIGH: 250-350
                    - üî¥ CRITICAL: > 350
                    """)

                with gr.Column(scale=2):
                    gr.Markdown("### üìä Results")

                    with gr.Row():
                        output_image = gr.Image(label="Annotated Feed")
                        heatmap_image = gr.Image(label="Heatmap")

                    with gr.Row():
                        zones_image = gr.Image(label="Safety Zones")
                        gauge_chart = gr.Plot(label="Crowd Gauge")

            gr.Markdown("---")
            report_output = gr.Markdown()

            with gr.Accordion("üö® Alerts", open=False):
                alert_table = gr.Dataframe()

            analyze_btn.click(
                fn=analyzer.analyze_image,
                inputs=[image_input, location_input, show_zones, show_contours],
                outputs=[output_image, heatmap_image, zones_image, gauge_chart, report_output, alert_table]
            )

        with gr.Tab("üé• Video Analysis"):
            with gr.Row():
                with gr.Column():
                    video_input = gr.Video(label="Upload Video")
                    location_input_video = gr.Textbox(value="Main Entrance", label="üìç Location")

                    with gr.Accordion("‚öôÔ∏è Options", open=False):
                        show_zones_video = gr.Checkbox(label="Show Zones", value=True)
                        show_contours_video = gr.Checkbox(label="Show Contours", value=False)

                    analyze_video_btn = gr.Button("üé¨ Analyze Video", variant="primary", size="lg")

                with gr.Column():
                    gr.Markdown("""
                    ### üé¨ Features
                    - Frame-by-frame analysis
                    - Timeline charts
                    - Peak detection
                    - Comprehensive report
                    """)

            gr.Markdown("---")
            output_video = gr.Video(label="Processed Video")

            with gr.Row():
                timeline_chart = gr.Plot(label="Timeline")
                distribution_chart = gr.Plot(label="Distribution")

            video_report_output = gr.Markdown()

            analyze_video_btn.click(
                fn=analyzer.analyze_video,
                inputs=[video_input, location_input_video, show_zones_video, show_contours_video],
                outputs=[output_video, timeline_chart, distribution_chart, video_report_output]
            )

    gr.Markdown("""
    ---
    <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px;'>
        <h3 style='color: white;'>Dhristi - Protecting Lives üíô</h3>
    </div>
    """)

print("üöÄ Launching Dhristi...")
demo.launch(share=True, debug=True)